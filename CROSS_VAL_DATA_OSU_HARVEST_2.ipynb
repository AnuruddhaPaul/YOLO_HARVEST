{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e448de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfe79a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      5\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, optim\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import os, time, shutil, gc, glob\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "\n",
    "os.environ['YOLO_VERBOSE'] = 'False'\n",
    "\n",
    "################################################################################\n",
    "# CONFIGURATION\n",
    "################################################################################\n",
    "DATA_ROOT = Path('DATASET')\n",
    "MODEL_SAVE_DIR = Path('SAVED_MODELS')\n",
    "MODEL_SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "IMAGE_SIZE_DET = 416\n",
    "IMAGE_SIZE_CLS = 224\n",
    "BATCH_SIZE = 12\n",
    "EPOCHS = 100\n",
    "PATIENCE = 75\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"OSU SMALL ANIMALS - YOLO-HARVEST TRAINING\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Image Size: {IMAGE_SIZE_CLS}x{IMAGE_SIZE_CLS}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_clean_dataset():\n",
    "    \"\"\"Load pre-validated clean dataset\"\"\"\n",
    "    cache_file = MODEL_SAVE_DIR / 'clean_samples.pkl'\n",
    "    \n",
    "    if not cache_file.exists():\n",
    "        print(\" Clean dataset not found!\")\n",
    "        print(\"Please run: python clean_dataset.py\")\n",
    "        raise FileNotFoundError(\"Run clean_dataset.py first!\")\n",
    "    \n",
    "    print(\"Loading clean dataset...\")\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    print(f\" Loaded {len(data['samples']):,} validated images\")\n",
    "    print(f\"   ({data['corrupted_count']} corrupted images excluded)\")\n",
    "    \n",
    "    return data['samples'], data['top_class_to_idx'], data['sub_class_to_idx']\n",
    "\n",
    "################################################################################\n",
    "# HARVEST COMPONENTS (PAPER-COMPLIANT)\n",
    "################################################################################\n",
    "\n",
    "class ShiftedPatchTokenization(nn.Module):\n",
    "    \"\"\" SPT - Paper Section 3.\"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=384):\n",
    "        super().__init__()\n",
    "        self.shift_convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_chans, embed_dim // 4, kernel_size=patch_size, stride=patch_size)\n",
    "            for _ in range(4)\n",
    "        ])\n",
    "        for conv in self.shift_convs:\n",
    "            nn.init.kaiming_normal_(conv.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if conv.bias is not None:\n",
    "                nn.init.constant_(conv.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        shifts = [(0, 0), (1, 0), (0, 1), (1, 1)]\n",
    "        shifted_features = []\n",
    "\n",
    "        for i, (sh, sw) in enumerate(shifts):\n",
    "            if sh > 0 or sw > 0:\n",
    "                padded = F.pad(x, (sw, 0, sh, 0))[:, :, :H, :W]\n",
    "            else:\n",
    "                padded = x\n",
    "            feature = self.shift_convs[i](padded)\n",
    "            shifted_features.append(feature)\n",
    "\n",
    "        return torch.cat(shifted_features, dim=1)\n",
    "\n",
    "\n",
    "class LocalInformationEnhancer(nn.Module):\n",
    "    \"\"\"LIFE - Paper Section 3.2\"\"\"\n",
    "    def __init__(self, embed_dim=384):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(embed_dim, embed_dim, 3, 1, 1, groups=embed_dim)\n",
    "        self.bn1 = nn.BatchNorm2d(embed_dim)\n",
    "        self.pwconv = nn.Conv2d(embed_dim, embed_dim, 1, 1, 0)\n",
    "        self.bn2 = nn.BatchNorm2d(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.bn1(self.dwconv(x)))\n",
    "        x = F.gelu(self.bn2(self.pwconv(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LocalityEnhancedAttention(nn.Module):\n",
    "    \"\"\" LEA - Paper Section 3.3\"\"\"\n",
    "    def __init__(self, dim, num_heads=6, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.local_mask = nn.Parameter(torch.randn(num_heads, 1, 1) * 0.02)\n",
    "        self.rescale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
    "        q, k, v = qkv[:, :, 0], qkv[:, :, 1], qkv[:, :, 2]\n",
    "        q, k, v = [t.permute(0, 2, 1, 3) for t in (q, k, v)]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        identity = torch.eye(N, device=x.device).unsqueeze(0).unsqueeze(0)\n",
    "        attn = attn + self.local_mask * identity\n",
    "        attn = attn * self.rescale\n",
    "\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CrossLevelAttention(nn.Module):\n",
    "    \"\"\"Cross-Level Attention for hierarchical consistency\"\"\"\n",
    "    def __init__(self, dim, num_heads=6, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_current, x_previous):\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            self.norm(x_current), \n",
    "            self.norm(x_previous), \n",
    "            self.norm(x_previous)\n",
    "        )\n",
    "        return x_current + self.dropout(attn_output)\n",
    "\n",
    "\n",
    "class HARVESTBlock(nn.Module):\n",
    "    \"\"\" Standard Transformer Block with LEA\"\"\"\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=3.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = LocalityEnhancedAttention(dim, num_heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class HierarchicalHARVESTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=224, embed_dim=384, depth=8, num_heads=6,\n",
    "                 num_top_classes=1, num_sub_classes=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.spt = ShiftedPatchTokenization(input_size, 16, 3, embed_dim)\n",
    "        self.life = LocalInformationEnhancer(embed_dim)\n",
    "\n",
    "        num_patches = (input_size // 16) ** 2\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            HARVESTBlock(embed_dim, num_heads, dropout=0.1)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.cross_level_attn = CrossLevelAttention(embed_dim, num_heads)\n",
    "        self.cross_level_position = depth // 2\n",
    "\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "        self.top_class_head = nn.Linear(embed_dim, num_top_classes)\n",
    "        self.sub_class_head = nn.Linear(\n",
    "            embed_dim + num_top_classes,\n",
    "            num_sub_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spt(x)\n",
    "        x = self.life(x)\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        x_mid = None\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            \n",
    "            if i == self.cross_level_position - 1:\n",
    "                x_mid = x.clone()\n",
    "            elif i == self.cross_level_position and x_mid is not None:\n",
    "                x = self.cross_level_attn(x, x_mid)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x_pooled = x.mean(dim=1)\n",
    "        x = self.dropout(x_pooled)\n",
    "\n",
    "        top_logits = self.top_class_head(x)\n",
    "        x_sub = torch.cat([x, top_logits], dim=-1)\n",
    "        sub_logits = self.sub_class_head(x_sub)\n",
    "\n",
    "        return top_logits, sub_logits\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# DATASET\n",
    "################################################################################\n",
    "\n",
    "class OSUHierarchicalDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode='train', img_size=IMAGE_SIZE_CLS):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.mode = mode\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.samples = []\n",
    "        self.top_class_to_idx = {}\n",
    "        self.sub_class_to_idx = {}\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Loading {mode.upper()} dataset from: {root_dir}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        self._scan_dataset()\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                A.RandomResizedCrop(size=(img_size, img_size), scale=(0.7, 1.0), p=1.0),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.3),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.7),\n",
    "                A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1, p=0.7),\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "                    A.GaussianBlur(blur_limit=(3, 7)),\n",
    "                    A.MotionBlur(blur_limit=7),\n",
    "                ], p=0.5),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(height=img_size, width=img_size),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "        print(f\" Dataset loaded: {len(self.samples)} samples\")\n",
    "        print(f\"   Top classes: {len(self.top_class_to_idx)}\")\n",
    "        print(f\"   Sub classes: {len(self.sub_class_to_idx)}\")\n",
    "        print(f\"    Corrupted images will be skipped during training\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "    def _scan_dataset(self):\n",
    "        top_class_idx = 0\n",
    "        sub_class_idx = 0\n",
    "\n",
    "        for top_class_dir in sorted(self.root_dir.iterdir()):\n",
    "            if not top_class_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            top_class_name = top_class_dir.name\n",
    "            if top_class_name not in self.top_class_to_idx:\n",
    "                self.top_class_to_idx[top_class_name] = top_class_idx\n",
    "                top_class_idx += 1\n",
    "\n",
    "            for sub_class_dir in sorted(top_class_dir.iterdir()):\n",
    "                if not sub_class_dir.is_dir():\n",
    "                    continue\n",
    "\n",
    "                sub_class_name = sub_class_dir.name\n",
    "                if sub_class_name not in self.sub_class_to_idx:\n",
    "                    self.sub_class_to_idx[sub_class_name] = sub_class_idx\n",
    "                    sub_class_idx += 1\n",
    "\n",
    "                image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}\n",
    "                for img_path in sub_class_dir.iterdir():\n",
    "                    if img_path.suffix in image_extensions:\n",
    "                        self.samples.append({\n",
    "                            'path': str(img_path),\n",
    "                            'top_class': self.top_class_to_idx[top_class_name],\n",
    "                            'sub_class': self.sub_class_to_idx[sub_class_name],\n",
    "                            'top_class_name': top_class_name,\n",
    "                            'sub_class_name': sub_class_name\n",
    "                        })\n",
    "\n",
    "        print(f\"   Found {len(self.samples)} images\")\n",
    "        print(f\"   Top-level classes: {list(self.top_class_to_idx.keys())}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        from PIL import ImageFile\n",
    "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "        \n",
    "        sample = self.samples[idx % len(self.samples)]\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            img = Image.open(sample['path'])\n",
    "            img.load()  # Force immediate load\n",
    "            img_rgb = img.convert('RGB')\n",
    "            img_array = np.array(img_rgb)\n",
    "            img.close()\n",
    "            \n",
    "            # Transform\n",
    "            transformed = self.transform(image=img_array)\n",
    "            img_tensor = transformed['image']\n",
    "            \n",
    "            return img_tensor, sample['top_class'], sample['sub_class'], sample['path']\n",
    "        \n",
    "        except:\n",
    "            # Return dummy on ANY error\n",
    "            return (\n",
    "                torch.zeros(3, self.img_size, self.img_size),\n",
    "                -1,  # Will be filtered out\n",
    "                -1,\n",
    "                \"ERROR\"\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def augment_to_median(dataset):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BALANCING STRATEGY: AUGMENT TO MEDIAN\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    sub_class_counts = Counter()\n",
    "    for sample in dataset.samples:\n",
    "        sub_class_counts[sample['sub_class_name']] += 1\n",
    "\n",
    "    counts_list = list(sub_class_counts.values())\n",
    "    median_count = int(np.median(counts_list))\n",
    "\n",
    "    print(f\"\\nSub-class distribution (BEFORE balancing):\")\n",
    "    print(f\"  Min: {min(counts_list)} | Max: {max(counts_list)} | Median: {median_count}\")\n",
    "\n",
    "    balanced_samples = list(dataset.samples)\n",
    "\n",
    "    import random\n",
    "    random.seed(42)\n",
    "\n",
    "    for sub_class_name, orig_count in sub_class_counts.items():\n",
    "        if orig_count < median_count:\n",
    "            class_samples = [s for s in dataset.samples if s['sub_class_name'] == sub_class_name]\n",
    "            needed = median_count - orig_count\n",
    "\n",
    "            print(f\"  {sub_class_name}: {orig_count} → {median_count} (+{needed})\")\n",
    "\n",
    "            for i in range(needed):\n",
    "                source_sample = random.choice(class_samples)\n",
    "                balanced_samples.append(source_sample.copy())\n",
    "\n",
    "    print(f\"\\n✅ Balanced: {len(dataset.samples)} → {len(balanced_samples)}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    return balanced_samples\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# YOLO-HARVEST MODEL \n",
    "################################################################################\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "except ImportError:\n",
    "    os.system('pip install --quiet ultralytics')\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "\n",
    "class YOLO_HARVEST_Production(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_top_classes, num_sub_classes, yolo_model='yolov8n.pt'):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        print(f\"\\n Loading YOLO detector: {yolo_model}\")\n",
    "        yolo_detector = YOLO(yolo_model)\n",
    "        \n",
    "        # Store YOLO in a way that doesn't interfere with nn.Module\n",
    "        object.__setattr__(self, '_yolo_detector', yolo_detector)\n",
    "        print(\" YOLO loaded (for production detection)\")\n",
    "\n",
    "        self.harvest = HierarchicalHARVESTClassifier(\n",
    "            input_size=IMAGE_SIZE_CLS,\n",
    "            embed_dim=384,\n",
    "            depth=8,\n",
    "            num_heads=6,\n",
    "            num_top_classes=num_top_classes,\n",
    "            num_sub_classes=num_sub_classes\n",
    "        )\n",
    "\n",
    "        print(f\" HARVEST initialized\")\n",
    "        print(f\"   Parameters: {self.harvest.count_parameters():,}\")\n",
    "        print(f\"   Cross-level attention:  Enabled\")\n",
    "        print(f\"   Progressive heads:  Enabled\")\n",
    "        print(f\"   Top classes: {num_top_classes}\")\n",
    "        print(f\"   Sub classes: {num_sub_classes}\\n\")\n",
    "\n",
    "    def forward(self, images_tensor, image_paths=None, use_yolo=False):\n",
    "        \"\"\"\n",
    "        Training mode: Direct classification (faster)\n",
    "        Production mode: YOLO detection + classification\n",
    "        \"\"\"\n",
    "        if use_yolo and image_paths is not None:\n",
    "            \n",
    "            yolo_detector = object.__getattribute__(self, '_yolo_detector')\n",
    "            batch_crops = []\n",
    "            for img_path in image_paths:\n",
    "                results = yolo_detector(img_path, verbose=False)\n",
    "                # TODO: Crop detected regions and classify\n",
    "                # For now, use full image\n",
    "                batch_crops.append(images_tensor)\n",
    "            \n",
    "            top_logits, sub_logits = self.harvest(images_tensor)\n",
    "        else:\n",
    "            \n",
    "            top_logits, sub_logits = self.harvest(images_tensor)\n",
    "\n",
    "        return top_logits, sub_logits\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# CHECKPOINT MANAGEMENT\n",
    "################################################################################\n",
    "\n",
    "def find_latest_checkpoint(save_dir):\n",
    "    checkpoint_pattern = str(save_dir / 'best_model_epoch_*.pth')\n",
    "    checkpoints = glob.glob(checkpoint_pattern)\n",
    "    \n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    \n",
    "    epoch_nums = []\n",
    "    for ckpt in checkpoints:\n",
    "        try:\n",
    "            epoch_str = ckpt.split('epoch_')[1].split('_')[0]\n",
    "            epoch_nums.append((int(epoch_str), ckpt))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not epoch_nums:\n",
    "        return None\n",
    "    \n",
    "    latest_epoch, latest_path = max(epoch_nums, key=lambda x: x[0])\n",
    "    return latest_path\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, checkpoint_path):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" RESUMING FROM CHECKPOINT\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    if 'scheduler_state_dict' in checkpoint and scheduler is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint.get('epoch', 0)\n",
    "    best_val_acc = checkpoint.get('val_sub_acc', 0.0)\n",
    "    \n",
    "    print(f\"Resumed from epoch: {start_epoch}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return start_epoch, best_val_acc\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TRAINING\n",
    "################################################################################\n",
    "\n",
    "class MetricsTracker:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.top_correct = 0\n",
    "        self.sub_correct = 0\n",
    "        self.total = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, top_preds, sub_preds, top_targets, sub_targets, loss_value):\n",
    "        if len(top_preds) > 0:\n",
    "            self.top_correct += (top_preds == top_targets).sum().item()\n",
    "            self.sub_correct += (sub_preds == sub_targets).sum().item()\n",
    "            self.total += len(top_targets)\n",
    "            self.losses.append(float(loss_value))\n",
    "\n",
    "    def get_top_accuracy(self):\n",
    "        return self.top_correct / self.total if self.total > 0 else 0.0\n",
    "\n",
    "    def get_sub_accuracy(self):\n",
    "        return self.sub_correct / self.total if self.total > 0 else 0.0\n",
    "\n",
    "    def get_avg_loss(self):\n",
    "        return np.mean(self.losses) if self.losses else 0.0\n",
    "\n",
    "\n",
    "def train_harvest(model, train_loader, val_loader, epochs=EPOCHS, resume_checkpoint=None):\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.harvest.parameters(), lr=0.001, weight_decay=0.05)\n",
    "    \n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    print(f\"✅ Using CosineAnnealingWarmRestarts scheduler\")\n",
    "    print(f\"   T_0=10 (restart every 10 epochs)\")\n",
    "    print(f\"   T_mult=2 (double restart period each time)\")\n",
    "    print(f\"   eta_min=1e-6 (minimum LR)\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    scaler = GradScaler() if DEVICE.type == 'cuda' else None\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_sub_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    if resume_checkpoint:\n",
    "        start_epoch, best_val_sub_acc = load_checkpoint(\n",
    "            model, optimizer, scheduler, resume_checkpoint\n",
    "        )\n",
    "        \n",
    "       \n",
    "        if best_val_sub_acc >= 0.69:  # If stuck around 69%\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 0.0008  # Boost LR\n",
    "            print(f\" LR boosted to 0.0008 to escape plateau at {best_val_sub_acc:.4f}\")\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        model.harvest.train()\n",
    "        train_metrics = MetricsTracker()\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for imgs, top_labels, sub_labels, paths in train_pbar:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            top_labels = top_labels.to(DEVICE, non_blocking=True)\n",
    "            sub_labels = sub_labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            valid_mask = (top_labels != -1) & (sub_labels != -1)\n",
    "            if not valid_mask.any():\n",
    "                continue\n",
    "\n",
    "            imgs = imgs[valid_mask]\n",
    "            top_labels = top_labels[valid_mask]\n",
    "            sub_labels = sub_labels[valid_mask]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            try:\n",
    "                if scaler:\n",
    "                    with autocast():\n",
    "                        top_logits, sub_logits = model(imgs)\n",
    "                        loss_top = criterion(top_logits, top_labels)\n",
    "                        loss_sub = criterion(sub_logits, sub_labels)\n",
    "                        loss = 0.3 * loss_top + 0.7 * loss_sub\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.harvest.parameters(), 1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    top_logits, sub_logits = model(imgs)\n",
    "                    loss_top = criterion(top_logits, top_labels)\n",
    "                    loss_sub = criterion(sub_logits, sub_labels)\n",
    "                    loss = 0.3 * loss_top + 0.7 * loss_sub\n",
    "\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.harvest.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                top_preds = torch.argmax(top_logits, dim=1)\n",
    "                sub_preds = torch.argmax(sub_logits, dim=1)\n",
    "\n",
    "                train_metrics.update(top_preds, sub_preds, top_labels, sub_labels, loss.item())\n",
    "\n",
    "                train_pbar.set_postfix({\n",
    "                    'Loss': f'{train_metrics.get_avg_loss():.4f}',\n",
    "                    'Top': f'{train_metrics.get_top_accuracy():.4f}',\n",
    "                    'Sub': f'{train_metrics.get_sub_accuracy():.4f}'\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Training error: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Validation phase\n",
    "        model.harvest.eval()\n",
    "        val_metrics = MetricsTracker()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]  ')\n",
    "            for imgs, top_labels, sub_labels, paths in val_pbar:\n",
    "                imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "                top_labels = top_labels.to(DEVICE, non_blocking=True)\n",
    "                sub_labels = sub_labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "                valid_mask = (top_labels != -1) & (sub_labels != -1)\n",
    "                if not valid_mask.any():\n",
    "                    continue\n",
    "\n",
    "                imgs = imgs[valid_mask]\n",
    "                top_labels = top_labels[valid_mask]\n",
    "                sub_labels = sub_labels[valid_mask]\n",
    "\n",
    "                try:\n",
    "                    top_logits, sub_logits = model(imgs)\n",
    "                    loss_top = criterion(top_logits, top_labels)\n",
    "                    loss_sub = criterion(sub_logits, sub_labels)\n",
    "                    loss = 0.3 * loss_top + 0.7 * loss_sub\n",
    "\n",
    "                    top_preds = torch.argmax(top_logits, dim=1)\n",
    "                    sub_preds = torch.argmax(sub_logits, dim=1)\n",
    "\n",
    "                    val_metrics.update(top_preds, sub_preds, top_labels, sub_labels, loss.item())\n",
    "\n",
    "                    val_pbar.set_postfix({\n",
    "                        'Loss': f'{val_metrics.get_avg_loss():.4f}',\n",
    "                        'Top': f'{val_metrics.get_top_accuracy():.4f}',\n",
    "                        'Sub': f'{val_metrics.get_sub_accuracy():.4f}'\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "        # Epoch summary\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        val_sub_acc = val_metrics.get_sub_accuracy()\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EPOCH {epoch+1}/{epochs} ({epoch_time:.1f}s)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"TRAIN - Loss: {train_metrics.get_avg_loss():.4f} | \"\n",
    "              f\"Top: {train_metrics.get_top_accuracy():.4f} | Sub: {train_metrics.get_sub_accuracy():.4f}\")\n",
    "        print(f\"VAL   - Loss: {val_metrics.get_avg_loss():.4f} | \"\n",
    "              f\"Top: {val_metrics.get_top_accuracy():.4f} | Sub: {val_sub_acc:.4f}\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "        if val_sub_acc > best_val_sub_acc:\n",
    "            best_val_sub_acc = val_sub_acc\n",
    "            patience_counter = 0\n",
    "\n",
    "            model_path = MODEL_SAVE_DIR / f'best_model_epoch_{epoch+1}_acc_{val_sub_acc:.4f}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),  #  Save scheduler state\n",
    "                'val_sub_acc': val_sub_acc,\n",
    "                'val_top_acc': val_metrics.get_top_accuracy()\n",
    "            }, model_path)\n",
    "\n",
    "            print(f\" BEST MODEL SAVED: {model_path.name}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement ({patience_counter}/{PATIENCE})\")\n",
    "\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "        if DEVICE.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING COMPLETED\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Best validation accuracy: {best_val_sub_acc:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# MAIN\n",
    "################################################################################\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n OSU SMALL ANIMALS - YOLO-HARVEST  TRAINING\")\n",
    "  \n",
    "\n",
    "    try:\n",
    "        latest_checkpoint = find_latest_checkpoint(MODEL_SAVE_DIR)\n",
    "        \n",
    "        if latest_checkpoint:\n",
    "            print(f\"\\n Found checkpoint: {latest_checkpoint}\")\n",
    "            resume = input(\"Resume training? (y/n): \").strip().lower()\n",
    "            if resume != 'y':\n",
    "                latest_checkpoint = None\n",
    "        else:\n",
    "            print(\"\\n No checkpoints found. Starting from scratch.\")\n",
    "\n",
    "        print(\"\\nLoading dataset...\")\n",
    "        all_samples_dataset = OSUHierarchicalDataset(DATA_ROOT, mode='train')\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_samples, val_samples = train_test_split(\n",
    "            all_samples_dataset.samples,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        print(f\"\\nDataset split:\")\n",
    "        print(f\"  Training: {len(train_samples)}\")\n",
    "        print(f\"  Validation: {len(val_samples)}\")\n",
    "\n",
    "        train_dataset = OSUHierarchicalDataset(DATA_ROOT, mode='train')\n",
    "        train_dataset.samples = train_samples\n",
    "        train_dataset.top_class_to_idx = all_samples_dataset.top_class_to_idx\n",
    "        train_dataset.sub_class_to_idx = all_samples_dataset.sub_class_to_idx\n",
    "\n",
    "        balanced_samples = augment_to_median(train_dataset)\n",
    "        train_dataset.samples = balanced_samples\n",
    "\n",
    "        val_dataset = OSUHierarchicalDataset(DATA_ROOT, mode='val')\n",
    "        val_dataset.samples = val_samples\n",
    "        val_dataset.top_class_to_idx = all_samples_dataset.top_class_to_idx\n",
    "        val_dataset.sub_class_to_idx = all_samples_dataset.sub_class_to_idx\n",
    "\n",
    "        mappings = {\n",
    "            'top_class_to_idx': all_samples_dataset.top_class_to_idx,\n",
    "            'sub_class_to_idx': all_samples_dataset.sub_class_to_idx\n",
    "        }\n",
    "        with open(MODEL_SAVE_DIR / 'class_mappings.json', 'w') as f:\n",
    "            json.dump(mappings, f, indent=2)\n",
    "        print(f\" Class mappings saved\\n\")\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "            num_workers=NUM_WORKERS, pin_memory=False, drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "            num_workers=NUM_WORKERS, pin_memory=False\n",
    "        )\n",
    "\n",
    "        num_top_classes = len(all_samples_dataset.top_class_to_idx)\n",
    "        num_sub_classes = len(all_samples_dataset.sub_class_to_idx)\n",
    "\n",
    "        model = YOLO_HARVEST_Production(num_top_classes, num_sub_classes).to(DEVICE)\n",
    "\n",
    "        model = train_harvest(\n",
    "            model, train_loader, val_loader, \n",
    "            epochs=EPOCHS, \n",
    "            resume_checkpoint=latest_checkpoint\n",
    "        )\n",
    "\n",
    "        print(\"\\n TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d87b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    roc_curve, auc, precision_recall_curve,\n",
    "    top_k_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# CONFIGURATION\n",
    "################################################################################\n",
    "\n",
    "DATA_ROOT = Path('DATASET')\n",
    "MODEL_PATH = Path('YOUR_TARINED_MODEL')\n",
    "CLASS_MAPPINGS = Path('class_mappings.json')\n",
    "EVAL_DIR = Path('EVALUATION_RESULTS')\n",
    "EVAL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"YOLO-HARVEST MODEL EVALUATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Model: {MODEL_PATH.name}\")\n",
    "print(f\"Results: {EVAL_DIR}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "################################################################################\n",
    "# LOAD MODEL AND DATA\n",
    "################################################################################\n",
    "\n",
    "def load_model_and_data():\n",
    "    \"\"\"Load trained model and validation dataset\"\"\"\n",
    "    \n",
    "    print(\"Loading class mappings...\")\n",
    "    with open(CLASS_MAPPINGS, 'r') as f:\n",
    "        mappings = json.load(f)\n",
    "    \n",
    "    top_class_to_idx = mappings['top_class_to_idx']\n",
    "    sub_class_to_idx = mappings['sub_class_to_idx']\n",
    "    \n",
    "    # Reverse mappings for display\n",
    "    idx_to_top_class = {v: k for k, v in top_class_to_idx.items()}\n",
    "    idx_to_sub_class = {v: k for k, v in sub_class_to_idx.items()}\n",
    "    \n",
    "    num_top_classes = len(top_class_to_idx)\n",
    "    num_sub_classes = len(sub_class_to_idx)\n",
    "    \n",
    "    print(f\"Classes: {num_top_classes} top-level, {num_sub_classes} sub-level\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model = YOLO_HARVEST_Production(\n",
    "        num_top_classes=num_top_classes,\n",
    "        num_sub_classes=num_sub_classes\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\" Model loaded (Epoch {checkpoint['epoch']}, Val Acc: {checkpoint['val_sub_acc']:.4f})\")\n",
    "    \n",
    "    # Load validation dataset\n",
    "    print(\"Loading validation dataset...\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    base_dataset = OSUHierarchicalDataset(DATA_ROOT, mode='train')\n",
    "    _, val_samples = train_test_split(\n",
    "        base_dataset.samples, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    val_dataset = OSUHierarchicalDataset(DATA_ROOT, mode='val')\n",
    "    val_dataset.samples = val_samples\n",
    "    val_dataset.top_class_to_idx = top_class_to_idx\n",
    "    val_dataset.sub_class_to_idx = sub_class_to_idx\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, \n",
    "        shuffle=False, num_workers=NUM_WORKERS, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    print(f\" Validation set: {len(val_dataset)} samples\\n\")\n",
    "    \n",
    "    return model, val_loader, idx_to_top_class, idx_to_sub_class\n",
    "\n",
    "################################################################################\n",
    "# PREDICTION AND METRICS COLLECTION\n",
    "################################################################################\n",
    "\n",
    "def collect_predictions(model, val_loader):\n",
    "    \"\"\"Collect all predictions and ground truth labels\"\"\"\n",
    "    \n",
    "    print(\"Collecting predictions...\")\n",
    "    \n",
    "    all_top_preds = []\n",
    "    all_top_labels = []\n",
    "    all_top_probs = []\n",
    "    \n",
    "    all_sub_preds = []\n",
    "    all_sub_labels = []\n",
    "    all_sub_probs = []\n",
    "    \n",
    "    all_paths = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, top_labels, sub_labels, paths in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            top_labels = top_labels.to(DEVICE, non_blocking=True)\n",
    "            sub_labels = sub_labels.to(DEVICE, non_blocking=True)\n",
    "            \n",
    "            # Filter valid samples\n",
    "            valid_mask = (top_labels != -1) & (sub_labels != -1)\n",
    "            if not valid_mask.any():\n",
    "                continue\n",
    "            \n",
    "            imgs = imgs[valid_mask]\n",
    "            top_labels = top_labels[valid_mask]\n",
    "            sub_labels = sub_labels[valid_mask]\n",
    "            paths = [p for i, p in enumerate(paths) if valid_mask[i]]\n",
    "            \n",
    "            # Forward pass\n",
    "            top_logits, sub_logits = model(imgs)\n",
    "            \n",
    "            # Top-level predictions\n",
    "            top_probs = F.softmax(top_logits, dim=1)\n",
    "            top_preds = torch.argmax(top_probs, dim=1)\n",
    "            \n",
    "            # Sub-level predictions\n",
    "            sub_probs = F.softmax(sub_logits, dim=1)\n",
    "            sub_preds = torch.argmax(sub_probs, dim=1)\n",
    "            \n",
    "            # Collect\n",
    "            all_top_preds.extend(top_preds.cpu().numpy())\n",
    "            all_top_labels.extend(top_labels.cpu().numpy())\n",
    "            all_top_probs.extend(top_probs.cpu().numpy())\n",
    "            \n",
    "            all_sub_preds.extend(sub_preds.cpu().numpy())\n",
    "            all_sub_labels.extend(sub_labels.cpu().numpy())\n",
    "            all_sub_probs.extend(sub_probs.cpu().numpy())\n",
    "            \n",
    "            all_paths.extend(paths)\n",
    "    \n",
    "    results = {\n",
    "        'top_preds': np.array(all_top_preds),\n",
    "        'top_labels': np.array(all_top_labels),\n",
    "        'top_probs': np.array(all_top_probs),\n",
    "        'sub_preds': np.array(all_sub_preds),\n",
    "        'sub_labels': np.array(all_sub_labels),\n",
    "        'sub_probs': np.array(all_sub_probs),\n",
    "        'paths': all_paths\n",
    "    }\n",
    "    \n",
    "    print(f\" Collected {len(all_sub_preds)} predictions\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "################################################################################\n",
    "# VISUALIZATION FUNCTIONS\n",
    "################################################################################\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title, save_path):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    \n",
    "    # Specify all labels to ensure matrix includes all classes\n",
    "    all_labels = list(range(len(class_names)))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n",
    "    \n",
    "    # Normalize\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Handle division by zero for classes with no samples\n",
    "    cm_norm = np.nan_to_num(cm_norm, nan=0.0)\n",
    "    \n",
    "    plt.figure(figsize=(20, 16))\n",
    "    sns.heatmap(cm_norm, annot=False, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Normalized Count'})\n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.xticks(rotation=90, ha='right', fontsize=8)\n",
    "    plt.yticks(rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\" Saved: {save_path.name}\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_per_class_accuracy(y_true, y_pred, class_names, title, save_path):\n",
    "    \"\"\"Plot per-class accuracy bar chart\"\"\"\n",
    "    \n",
    "    per_class_acc = []\n",
    "    for i in range(len(class_names)):\n",
    "        mask = y_true == i\n",
    "        if mask.sum() > 0:\n",
    "            acc = (y_pred[mask] == i).sum() / mask.sum()\n",
    "            per_class_acc.append(acc)\n",
    "        else:\n",
    "            per_class_acc.append(0.0)\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    sorted_indices = np.argsort(per_class_acc)\n",
    "    sorted_names = [class_names[i] for i in sorted_indices]\n",
    "    sorted_accs = [per_class_acc[i] for i in sorted_indices]\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    colors = ['red' if acc < 0.7 else 'orange' if acc < 0.85 else 'green' \n",
    "              for acc in sorted_accs]\n",
    "    plt.barh(sorted_names, sorted_accs, color=colors, alpha=0.7)\n",
    "    plt.xlabel('Accuracy', fontsize=14)\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.axvline(x=np.mean(sorted_accs), color='blue', linestyle='--', \n",
    "                linewidth=2, label=f'Mean: {np.mean(sorted_accs):.4f}')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved: {save_path.name}\")\n",
    "    \n",
    "    return per_class_acc\n",
    "\n",
    "\n",
    "def plot_roc_curves(y_true, y_probs, class_names, title, save_path, max_classes=10):\n",
    "    \"\"\"Plot ROC curves for top classes\"\"\"\n",
    "    \n",
    "    # Binarize labels with all possible classes\n",
    "    all_labels = list(range(len(class_names)))\n",
    "    y_true_bin = label_binarize(y_true, classes=all_labels)\n",
    "    \n",
    "    # Calculate ROC curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(len(class_names)):\n",
    "        # Skip classes with no samples\n",
    "        if y_true_bin[:, i].sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        except ValueError:\n",
    "            # Handle edge cases\n",
    "            continue\n",
    "    \n",
    "    # Plot top N classes by sample count\n",
    "    class_counts = np.bincount(y_true, minlength=len(class_names))\n",
    "    top_classes = np.argsort(class_counts)[::-1][:max_classes]\n",
    "    \n",
    "    # Filter to only classes we have ROC data for\n",
    "    top_classes = [i for i in top_classes if i in fpr]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in top_classes:\n",
    "        plt.plot(fpr[i], tpr[i], linewidth=2,\n",
    "                label=f'{class_names[i][:20]} (AUC={roc_auc[i]:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\" Saved: {save_path.name}\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_precision_recall_curves(y_true, y_probs, class_names, title, save_path, max_classes=10):\n",
    "    \"\"\"Plot Precision-Recall curves\"\"\"\n",
    "    \n",
    "    all_labels = list(range(len(class_names)))\n",
    "    y_true_bin = label_binarize(y_true, classes=all_labels)\n",
    "    \n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    pr_auc = dict()\n",
    "    \n",
    "    for i in range(len(class_names)):\n",
    "        # Skip classes with no samples\n",
    "        if y_true_bin[:, i].sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "            pr_auc[i] = auc(recall[i], precision[i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    class_counts = np.bincount(y_true, minlength=len(class_names))\n",
    "    top_classes = np.argsort(class_counts)[::-1][:max_classes]\n",
    "    \n",
    "    # Filter to only classes we have PR data for\n",
    "    top_classes = [i for i in top_classes if i in precision]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in top_classes:\n",
    "        plt.plot(recall[i], precision[i], linewidth=2,\n",
    "                label=f'{class_names[i][:20]} (AUC={pr_auc[i]:.3f})')\n",
    "    \n",
    "    plt.xlabel('Recall', fontsize=14)\n",
    "    plt.ylabel('Precision', fontsize=14)\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.legend(loc=\"lower left\", fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\" Saved: {save_path.name}\")\n",
    "\n",
    "\n",
    "def analyze_errors(results, idx_to_top, idx_to_sub, save_path):\n",
    "    \"\"\"Analyze common misclassifications\"\"\"\n",
    "    \n",
    "    sub_labels = results['sub_labels']\n",
    "    sub_preds = results['sub_preds']\n",
    "    \n",
    "    # Find misclassified samples\n",
    "    wrong_mask = sub_labels != sub_preds\n",
    "    wrong_true = sub_labels[wrong_mask]\n",
    "    wrong_pred = sub_preds[wrong_mask]\n",
    "    \n",
    "    # Count misclassification pairs\n",
    "    error_pairs = {}\n",
    "    for true, pred in zip(wrong_true, wrong_pred):\n",
    "        pair = (true, pred)\n",
    "        error_pairs[pair] = error_pairs.get(pair, 0) + 1\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_errors = sorted(error_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Top 20 errors\n",
    "    top_errors = sorted_errors[:20]\n",
    "    \n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'True Class': idx_to_sub[pair[0]],\n",
    "            'Predicted Class': idx_to_sub[pair[1]],\n",
    "            'Count': count\n",
    "        }\n",
    "        for pair, count in top_errors\n",
    "    ])\n",
    "    \n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\" Saved: {save_path.name}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_top_k_accuracy(y_true, y_probs, k_values=[1, 3, 5, 10], save_path=None):\n",
    "    \"\"\"Plot Top-K accuracy\"\"\"\n",
    "    \n",
    "    # Get total number of classes from y_probs shape\n",
    "    num_classes = y_probs.shape[1]\n",
    "    all_labels = list(range(num_classes))\n",
    "    \n",
    "    top_k_accs = []\n",
    "    for k in k_values:\n",
    "        # Pass labels parameter to handle missing classes\n",
    "        acc = top_k_accuracy_score(y_true, y_probs, k=k, labels=all_labels)\n",
    "        top_k_accs.append(acc)\n",
    "        print(f\"  Top-{k} Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    if save_path:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(k_values, top_k_accs, marker='o', linewidth=3, markersize=10)\n",
    "        plt.xlabel('K (Top-K)', fontsize=14)\n",
    "        plt.ylabel('Accuracy', fontsize=14)\n",
    "        plt.title('Top-K Classification Accuracy', fontsize=16, fontweight='bold')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\" Saved: {save_path.name}\")\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# MAIN EVALUATION\n",
    "################################################################################\n",
    "\n",
    "def run_evaluation():\n",
    "    \"\"\"Run complete evaluation\"\"\"\n",
    "    \n",
    "    # Load model and data\n",
    "    model, val_loader, idx_to_top, idx_to_sub = load_model_and_data()\n",
    "    \n",
    "    # Collect predictions\n",
    "    results = collect_predictions(model, val_loader)\n",
    "    \n",
    "    # Extract data\n",
    "    top_labels = results['top_labels']\n",
    "    top_preds = results['top_preds']\n",
    "    top_probs = results['top_probs']\n",
    "    \n",
    "    sub_labels = results['sub_labels']\n",
    "    sub_preds = results['sub_preds']\n",
    "    sub_probs = results['sub_probs']\n",
    "    \n",
    "    # Class names\n",
    "    top_class_names = [idx_to_top[i] for i in range(len(idx_to_top))]\n",
    "    sub_class_names = [idx_to_sub[i] for i in range(len(idx_to_sub))]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EVALUATION METRICS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Overall accuracy\n",
    "    top_acc = (top_preds == top_labels).mean()\n",
    "    sub_acc = (sub_preds == sub_labels).mean()\n",
    "    \n",
    "    print(f\"Top-Level Accuracy:  {top_acc:.4f} ({top_acc*100:.2f}%)\")\n",
    "    print(f\"Sub-Level Accuracy:  {sub_acc:.4f} ({sub_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Top-K accuracy\n",
    "    print(\"\\nTop-K Sub-Class Accuracy:\")\n",
    "    plot_top_k_accuracy(sub_labels, sub_probs, k_values=[1, 3, 5, 10], \n",
    "                       save_path=EVAL_DIR / 'top_k_accuracy.png')\n",
    "    \n",
    "    # Confusion matrices\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        top_labels, top_preds, top_class_names,\n",
    "        'Top-Level Classification Confusion Matrix',\n",
    "        EVAL_DIR / 'confusion_matrix_top.png'\n",
    "    )\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        sub_labels, sub_preds, sub_class_names,\n",
    "        'Sub-Level Classification Confusion Matrix (45 Classes)',\n",
    "        EVAL_DIR / 'confusion_matrix_sub.png'\n",
    "    )\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    per_class_acc_top = plot_per_class_accuracy(\n",
    "        top_labels, top_preds, top_class_names,\n",
    "        'Per-Class Accuracy - Top Level (7 Classes)',\n",
    "        EVAL_DIR / 'per_class_accuracy_top.png'\n",
    "    )\n",
    "    \n",
    "    per_class_acc_sub = plot_per_class_accuracy(\n",
    "        sub_labels, sub_preds, sub_class_names,\n",
    "        'Per-Class Accuracy - Sub Level (45 Classes)',\n",
    "        EVAL_DIR / 'per_class_accuracy_sub.png'\n",
    "    )\n",
    "    \n",
    "    # ROC curves\n",
    "    plot_roc_curves(\n",
    "        sub_labels, sub_probs, sub_class_names,\n",
    "        'ROC Curves - Top 10 Sub-Classes by Sample Count',\n",
    "        EVAL_DIR / 'roc_curves_sub.png',\n",
    "        max_classes=10\n",
    "    )\n",
    "    \n",
    "    # Precision-Recall curves\n",
    "    plot_precision_recall_curves(\n",
    "        sub_labels, sub_probs, sub_class_names,\n",
    "        'Precision-Recall Curves - Top 10 Sub-Classes',\n",
    "        EVAL_DIR / 'precision_recall_sub.png',\n",
    "        max_classes=10\n",
    "    )\n",
    "    \n",
    "    # Error analysis\n",
    "    error_df = analyze_errors(\n",
    "        results, idx_to_top, idx_to_sub,\n",
    "        EVAL_DIR / 'top_20_errors.csv'\n",
    "    )\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nGenerating classification reports...\")\n",
    "\n",
    "# Specify all possible labels to handle missing classes\n",
    "    all_sub_labels = list(range(len(sub_class_names)))\n",
    "\n",
    "    report_sub = classification_report(\n",
    "        sub_labels, sub_preds, \n",
    "        target_names=sub_class_names,\n",
    "        labels=all_sub_labels,\n",
    "        zero_division=0,  # Handle classes with no support\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    df_report = pd.DataFrame(report_sub).transpose()\n",
    "    df_report.to_csv(EVAL_DIR / 'classification_report_sub.csv')\n",
    "    print(f\"✅ Saved: classification_report_sub.csv\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'top_level_accuracy': float(top_acc),\n",
    "        'sub_level_accuracy': float(sub_acc),\n",
    "        'num_samples': len(sub_labels),\n",
    "        'num_top_classes': len(top_class_names),\n",
    "        'num_sub_classes': len(sub_class_names),\n",
    "        'per_class_accuracy_sub': {\n",
    "            sub_class_names[i]: float(per_class_acc_sub[i]) \n",
    "            for i in range(len(sub_class_names))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(EVAL_DIR / 'evaluation_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\" Saved: evaluation_summary.json\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EVALUATION COMPLETE!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Results saved to: {EVAL_DIR}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# MAIN EXECUTION\n",
    "################################################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        run_evaluation()\n",
    "        print(\"\\n🎉 Evaluation completed successfully!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
